---
title: "Storm Effects on Communities, Analysis"
author: "Anandu R"
date: "8/6/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Storms and other severe weather events can cause both public health and economic
problems for communities and municipalities. Many severe events can result in
fatalities, injuries, and property damage, and preventing such outcomes to the 
extent possible is a key concern.

This project involves exploring the U.S. National Oceanic and Atmospheric
Administration's (NOAA) storm database. This database tracks characteristics of 
major storms and weather events in the United States, including when and where 
they occur, as well as estimates of any fatalities, injuries, and property
damage.

## Data Processing 
There is also some documentation of the database available. Details on how some 
of the variables are constructed/defined is available on this website by
National Weather Service : [Storm Data Documentation]("https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf")

### Getting the data 
```{r}
fileUrl = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./data/data.csv.bz2")){
  download.file(fileUrl,"./data/data.csv.bz2")
}
```

### Reading the data
```{r,cache=T}
data_raw <- read.csv("./data/data.csv.bz2", sep =",", header = T)
```

#### Preliminary analysis of data

```{r}
head(data_raw)
```

Reading column names 
```{r}
names(data_raw)
```


### Data Cleaning 
#### Checking distrobution of Missing data and NAs in the dataset 
```{r}
datatypes = as.character(sapply(data_raw, class))
character_loc = which(datatypes == "character")
arr_missing = array(dim = length(character_loc))
j=1
for(i in character_loc){
  arr_missing[j] = mean(data_raw[,i]=="")
  j = j+1
}
arr_missing_r = character_loc[which(arr_missing*100 < 2 & arr_missing > 0)]
arr_missing_c = character_loc[which(arr_missing*100 > 50)]
arr_NAs_r = which(as.numeric(colMeans(is.na(data_raw))) > 0 & as.numeric(colMeans(is.na(data_raw)))*100 < 2)
arr_NAs_c = which(as.numeric(colMeans(is.na(data_raw)))*100 > 50)
arr_missing
```
#### Removing columns that have more that 50% data misssing
Columns 26, and 28 represent the "PROPDMGEXP", "CROPDMGEXP" fields which are
required for the analysis therefore we will keep them.
```{r}
arr_missing_c = arr_missing_c[-c(4,5)]
data_clean = data_raw[,-c(arr_missing_c,arr_NAs_c)]
```

Since the END_DATE and END_TIME fields are same as the BGN_DATA and BGN_TIME, we 
also remove those columns from the data.

Furthermore, since the COUNTY_END field has only the value 0 and would serve no
purpose to the analysis, it too is removed

```{r}
data_clean = data_clean[,-c(11:13)]
```


#### Removing records with missing or NA data
```{r}
with_NAs = complete.cases(data_raw[,arr_NAs_r])
data_clean = subset(data_clean, with_NAs)
data_clean = data_clean[!(data_clean[,arr_missing_r]==""),]
```

Checking distribution of missing value and NAs
```{r, cache=T}
as.numeric(colMeans(is.na(data_clean)))
as.numeric(colMeans(data_clean==""))
```
There are still some fields with no value aka missing values in certain columns,
but their percentages are in range 10-50% so the next suitable step would be to 
impute the values in the dataset, but since it is the weather data, imputing 
values would only create noise in the data(?)

Looking at cleaned data 
```{r}
head(data_clean)
```

### Fixing the datatypes and datafields

#### Creating a datatime field
```{r, cache= T}
data_clean$BGN_DATE = as.POSIXct(data_clean$BGN_DATE, format = "%m/%d/%Y %H:%M:%S")
data_clean$BGN_TIME = format(strptime(data_clean$BGN_TIME,"%H%M"),'%H:%M')
data_clean$BGN_DATETIME = as.POSIXct(paste(data_clean$BGN_DATE, data_clean$BGN_TIME), format="%Y-%m-%d %H:%M")
```

#### Imputing proper values in the "PROPDMGEXP", "CROPDMGEXP" fields
Current values in "CROPDMGEXP"
```{r}
unique(data_clean$CROPDMGEXP)
```
Current values in "PROPDMGEXP"
```{r}
unique(data_clean$PROPDMGEXP)
```
Correct representations:
- "\"\"" = 10^0,
- "-" = 10^0, 
- "?" = 10^0,
- "+" = 10^0,
- "0" = 10^0,
- "1" = 10^1,
- "2" = 10^2,
- "3" = 10^3,
- "4" = 10^4,
- "5" = 10^5,
- "6" = 10^6,
- "7" = 10^7,
- "8" = 10^8,
- "9" = 10^9,
- "H" = 10^2,
- "K" = 10^3,
- "M" = 10^6,
- "B" = 10^9

Imputing the correct values 
```{r}
data_clean = transform(data_clean, PROPDMGEXP = toupper(PROPDMGEXP), CROPDMGEXP = toupper(CROPDMGEXP))
DmgExP =  c("\"\"" = 10^0,
            "-" = 10^0, 
            "+" = 10^0,
            "?" = 10^0,
            "0" = 10^0,
            "1" = 10^1,
            "2" = 10^2,
            "3" = 10^3,
            "4" = 10^4,
            "5" = 10^5,
            "6" = 10^6,
            "7" = 10^7,
            "8" = 10^8,
            "9" = 10^9,
            "H" = 10^2,
            "K" = 10^3,
            "M" = 10^6,
            "B" = 10^9)
data_clean = transform(
  data_clean, 
  PROPDMGEXP = as.numeric(DmgExP[as.character(data_clean[,"PROPDMGEXP"])]),
  CROPDMGEXP = as.numeric(DmgExP[as.character(data_clean[,"CROPDMGEXP"])])
)
data_clean = transform(
  data_clean,
  PROPDMGEXP = ifelse(is.na(PROPDMGEXP),10^0,PROPDMGEXP),
  CROPDMGEXP = ifelse(is.na(CROPDMGEXP),10^0,CROPDMGEXP)
)
```


### Subsetting the data, removing EVTYPEs that have 0 impact of any sort

```{r}
data_clean = subset(data_clean, EVTYPE != "?" &  (INJURIES > 0 | FATALITIES > 0 | PROPDMG > 0 | CROPDMG > 0))
```


Aggregating the results
```{r}
library(dplyr)
data_ = data_clean %>%
  group_by(EVTYPE) %>%
  summarise(
    FATALITIES = sum(FATALITIES, na.rm = T),
    INJURIES = sum(INJURIES,na.rm = T),
    CROPDMG = sum(CROPDMG, na.rm = T),
    PROPDMG = sum(PROPDMG, na.rm = T)
  )
data_
```


## Exploratory Analysis 

```{r}
names(data_clean)
```

### Analyis to find events that are most harmful with respect to population health

Looking at data in relavant columns "FATALITIES" and "INJURIES"
```{r}
head(data_clean[,c("EVTYPE","FATALITIES","INJURIES")])
```





## Removing data file after analysis
```{r}
unlink("./data/data.csv.bz2",recursive = T)
#unlink("./analysis_cache", recursive = T)
```

