---
title: "Practicality of Statistical Inference"
author: "Anandu R"
date: "8/25/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## examples of PDFs
### Example 1

Consider the function to denote the probability of help calls addressed by a 
helpline be 
```
  f(x) = {2x for 0<x<1; 0 otherwise}
``` 
```{r, echo=FALSE}
x = c(-0.5,0,1,1,1.5)
y = c(0,0,2,0,0)
plot(x, y, type = "l", frame = F)
```   

To find probability that 75% or fewer of calls get addressed   

```{r, echo=FALSE}
plot(x, y, type = "l", frame = F)
lines(c(0,0.75,0.75),c(0,0,1.5), col = "skyblue")
```  

Find area of given portion 
```
  (1/2)*(0.75)*(1.5)
  = 0.5625
```

The same can be achieved by using the beta function for probability - pbeta()  
```{r, results=F}
pbeta(0.75,2,1)
```  
The quantile for the above population distribution  
Median from the distribution shows the datapoint below which 50% of the data is 
present and above it is the other 50%

```
  0.5 = F(X) = P(X<=x) = 50% of the area
  Integrating the function F(X)=2x, we get x^2
  => x = sqrt(2) = 0.707
  => The required datapoint
```  

The same can be found out using the qbeta() function which gives the quantile of
the beta distribution
```{r, results=F}
qbeta(0.5,2,1)
```

The inference is that during 50% of the day ~70% of the calls are addressed. 


## Real World Example of Statistical Inference

Using the Son's Height attribute from the father.son data  

### Loading the data 
```{r, results=F, warning=F}
## Loading the data
suppressMessages(
  {
    if(!require('UsingR')){
      install.packages('UsingR')
      library(UsingR); data(father.son)
    }
    if(!require('dplyr')){
      install.packages("dplyr")
      library(dplyr)
    }
  }
)
x = father.son$sheight
n = length(x)
```

### Plot of heights
```{r}
ggplot() + geom_histogram(aes(x), col = "white", fill = "skyblue") + theme_bw()
```  

The height is represented in feet instead of inches, divide the height by 12 to
convert to feet unit

```{r}
round(c(var(x),var(x)/n,sd(x),sd(x)/sqrt(n)),2)
```
## Explaining confidence intervals
```{r}
(mean(x)+c(-1,1)*qnorm(0.975)*sd(x)/sqrt(length(x)))/12
```  
This tells us that if we were to iid draw the sons from this population the CI 
for drawing an average height to the sons would in the interval 5.71 to 5.74

**Sample Proportions**: In an event that each Xi is 0 or 1(binary outcome), with 
common success probability p, then variance(sigma^2) = p(1-p)   
Then the interval takes the form   
Wald confidence interval for p - For 95% intervals is:  
```
  ^p (+/-) 1/sqrt(n)
```
which is a quick CI estimate for p 

## Confidence interval example
Your campaign advisor told you that in a random sample of 100 likely voters, 56 
intend to vote for you.
- Can you relax? Do you have this race in the bag?
- without access to a computer or calculator, how precise is the estimate?

Using Wald confidence, 1/(sqrt(100)) gives 0.1 confidence interval of 
[0.46,0.66] 
- Not enoug for you to relax, we can't rule out possibilities below 0.5 with 95%
confidence, better go do more campaigning. 

The above calculation of CI can be done using the binom.test() function in R
```{r}
binom.test(56,100)$conf.int
```  

Yielding a similar result as before. Mathematically which is 
```{r}
0.56 + c(-1,1)*qnorm(0.975)*sqrt(0.56*0.44/100)
```  


## Biased coin flip estimation using Wald's Confidence
varying p value to find the p val where estimator within confidence interval of 
the parameter mu,

```{r}
flips_per_sim = 20
pvals = seq(0.1,0.9,by = 0.05)
n_sim = 100000
coverage = sapply(pvals, function(p){
  phats = rbinom(n_sim, prob = p, size = flips_per_sim)/flips_per_sim
  ll = phats - qnorm(0.975)*sqrt(phats*(1-phats)/flips_per_sim)
  ul = phats + qnorm(0.975)*sqrt(phats*(1-phats)/flips_per_sim)
  mean(ll<p & ul>p)
})
plot(pvals, coverage, type = "l", lwd = 3)
abline(h = 0.95)
abline(v = 0.5, lty = 2)
```   

this shows that when n, the number of flips, is small (20) the CLT doesn't hold 
for many values of p, so the Wald interval doesn't work very well.  
When we increase n, the number of coin flips in each of our 1000 trials, from 20 
to 100 to see if the plot improves. Again, results may vary, but all the 
probabilities are much closer to the 95% line, so the CLT works better with a 
bigger value of n

```{r}
flips_per_sim = 1000
pvals = seq(0.1,0.9,by = 0.05)
n_sim = 100000
coverage = sapply(pvals, function(p){
  phats = rbinom(n_sim, prob = p, size = flips_per_sim)/flips_per_sim
  ll = phats - qnorm(0.975)*sqrt(phats*(1-phats)/flips_per_sim)
  ul = phats + qnorm(0.975)*sqrt(phats*(1-phats)/flips_per_sim)
  mean(ll<p & ul>p)
})
plot(pvals, coverage, type = "l", lwd = 3)
abline(h = 0.95)
abline(v = 0.5, lty = 2)
```   

A quick fix to the problem of having a small n is to use the Agresti/Coull 
interval. This simply means we add 2 successes and 2 failures to the counts when 
calculating the proportion p'. It is to be noted that although this works, the 
technique might make the confidence interval too wide.  
Why does this work? Adding 2 successes and 2 failures pulls p' closer to .5
which, as we saw, is the value which maximizes the confidence interval.


### Understanding T confidence by performing a paired T-Test

The sleep data, is used to analyse the change in sleeping periods of patients 
under the influence of two separate drugs hence explaining the groups field 
of factor datatype containing two levels 1 and 2.  
Here the pairing is between the two groups that have the same patient with ID 1 
represented by ID 11 in the group 2.   
This allows us to study the variations of effects of the drugs on the same
patients. 
```{r}
data("sleep")
head(sleep)
```

Plotting the difference in the sleep period   
```{r}
ggplot(
  sleep,
  aes(
    x = group,
    y = extra,
    group = ID
  )
) + geom_point(aes(col = ID), pch = 19, cex = 2.5) + geom_path(aes(col = ID))
```
  
Calculating the mean, variance and standard deviation between the results of the 
two groups.  
```{r}
g1 <- sleep$extra[1 : 10]; g2 <- sleep$extra[11 : 20]
difference <- g2 - g1
mn <- mean(difference); s <- sd(difference); n <- 10
```

Calculating the T confidence   
```{r}
mn + c(-1, 1) * qt(.975, n-1) * s / sqrt(n)
t.test(difference)
t.test(g2, g1, paired = TRUE)
t.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = sleep)
```  
Which tells us that there is difference in the heights.
## Understanding T intervals
Consider a test comparing the SBP(standard blood pressure) for 8 oral contraceptive users versus 21 
controls.   
**X**oc = 132.86 mmHg with **s**oc = 15.34
**X**c = 127.44 mmHg with **s**c = 18.23
We are required to find out using this sample the T-confidence interval for the 
average difference in the two independent groups. If the interval >= 0, then we 
can confidently state that the drug causes increase in blood pressure population.

```{r}
sp = sqrt((7*15.34^2+20*18.23^2)/(8+21-2))
132.86 - 127.44 + c(-1,1)*qt(0.975,27)*sp*sqrt(1/8+1/21)
```  
Since the above interval contains 0, there is possibility that there is 0 
difference between the population of the two groups. 

## Power explained
Supposed we were to calculate the probability of the sample mean to be 32, given 
that the population mean is 30 with standard deviation(sigma) 4 and number of samples 
drawn to be 16, we'd use the pnorm() function with mean = 30 and 
sd = sigma/sqrt(16)   
Then, 
```{r}
mu0 = 30
mua = 32
sigma = 4
n = 16
alpha = 0.05
z = qnorm(1-alpha)
pnorm(mu0+z*sigma/sqrt(n), mean = mu0, sd = sigma/sqrt(n), lower.tail = F)
```  
This tells us that we fail to reject the null hypothesis because the t-statistic 
is equal to alpha.

Now to calculate power, we simply replace the mean m0 with ma,
```{r}
pnorm(mu0+z*sigma/sqrt(n), mean = mua, sd = sigma/sqrt(n), lower.tail = F)
```  
This gives us power, the percent probability with which we can assure that the 
null hypothesis is not true, generally you should have an 80% or greater chance 
of finding a statistically significant difference when there is one.


## Illustrating the error correction in multiple comparison test cases
```{r}
set.seed(1010093)
## Creating NULL vector for p-values, we simulate 1000 hypothesis tests
pValues = rep(NULL,1000)
for(i in 1:1000){
  ## Generating two independent normals x and y
  x = rnorm(20)
  y = rnorm(20)
  ## Fitting a linear model relating the two variables 
  pValues[i] = summary(lm(y~x))$coeff[2,4]
}
sum(pValues<0.05)
```  
We get the expected ~50 significant p-values, while performing 1000 tests with
confidence 0.05, which gives us 1000*0.05=50 i.e the chance of there being false 
positives.  

**Adjusting the p-values**
- Using bonferroni correction 
```{r}
## Controls FWER
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
```
- Using Benjamini Hochberg correction
```{r}
## Controls FDR
sum(p.adjust(pValues, method = "BH") < 0.05)
```
In case there is strong dependence between tests there may be problems when 
using the "bonferroni" or the "BH" methods, we should consider using "BY" under
such circumstances.  
  
## Boostrapping Illustrated with father.son dataset
```{r}
suppressMessages(
  {
    library(UsingR)
    data(father.son)
  }
) 
x = father.son$sheight
n = length(x)
## We are performing 10000 bootstrap resamples
B = 10000
# We extract n times B samples with replacement, split the entire sample vector 
# into multiple vectors of length n, then store each B sample vectors as rows
# of a matrix, here named 'resamples'
resamples = matrix(sample(x, n*B, replace = T),B,n) 
## we then calculate the row medians and store in new vector resampledMedians
resampledMedians = apply(resamples, 1, median)
```

Visualising the vector of medians
```{r}
d = density(resampledMedians)
plot(d, main = "Density of median heights of sons", xlab = "Heights")
polygon(d, col="red", border="orange")
abline(v = median(resampledMedians), lwd = 2)
```    

The estimated standard deviation can be found 
```{r}
sd(resampledMedians)
```
Confidence interval
```{r}
quantile(resampledMedians,c(0.025,0.975))
```

## Illustration of permutation test
Consider the InsectSprays dataset, which contains details of counts of insects 
killed by different bug-sprays.
```{r}
data("InsectSprays")
head(InsectSprays)
```  

We subset the dataset to only get count of bugs killed by bug-spray 'B' and 'C' 
and define our variables 'x' and 'group'.
```{r}
subset = subset(InsectSprays, spray %in% c("B","C"))
x = subset$count
group = as.character(subset$spray)

```



If we take mean of count of insects killed by 
each group of bug-sprays we know that each group of bug-spray has different 
means by the boxplot below
```{r}
ggplot(
  InsectSprays,
  aes(
    x = spray,
    y = count
  )
) + geom_boxplot(aes(fill = spray))
```   

We wish to show that the bug-spray has effect on count on bugs killed, we
consider the null hypothesis that the means of the two sprays were equal and the
group label is unrelated to the  outcome.  
So if we were to permute the labels and find permutations of labels that have 
higher mean difference than what we get compared to current group label then we 
can disapprove the null hypothesis.  
```{r}
## Function to compare the mean of each group given set of group labels
testStat = function(x,g){
  mean(x[g=='B'])-mean(x[g=='C'])
}
## Observing the difference in mean for the observed data
observedStat = testStat(x, group)
## finding various permutations on the group labels and finding the mean 
## differences for each
permutations = sapply(1:10000, function(i) testStat(x,sample(group))) # This 
# vector would cantain the mean difference in 10000 permutations groups B and C 
# labels
print(paste('Observed mean difference:',as.character(observedStat)))
print(paste0('Percentage of permutation that have higher mean difference: ',as.character(mean(permutations>observedStat)),'%'))

```  
Hence we are able to reject the null hypothesis that the means of the two sprays
were equal and that the group labels have no effect on the outcome.

```{r}
ggplot(
  data.frame(permutations),
  aes(x = permutations),
) + coord_cartesian(xlim = c(-11,14)) +
  geom_histogram(bins = 20,fill="orange") + 
  geom_vline(aes(xintercept=observedStat),col = "red")
```   

We observe from the plot that the observed statistic is  far ahead of the 
normal distribution of the permutations.



## Examples
### Example 1
A pharmaceutical company is interested in testing a potential blood pressure lowering medication. Their first examination considers only subjects that received the medication at baseline then two weeks later. 
```{r}
pharmaData = data.frame(subject = c(1,2,3,4,5), Baseline = c(140,138,150,148,135),Week.2 = c(132,135,151,146,130))
t.test(pharmaData$Baseline,pharmaData$Week.2,paired = T, var.equal = T)
```  

### Example 2
A sample of 9 men yielded a sample average brain volume of 1,100cc and a standard deviation of 30cc. What is the complete set of values of <img src="https://render.githubusercontent.com/render/math?math=$\mu_{0}$"> that a test of <img src="https://render.githubusercontent.com/render/math?math=$H_{0}:\mu=\mu_{0}$"> would fail to reject the null hypothesis in a two sided 5% Students t-test?
```{r}
1100 + c(-1,1)*qt(0.975,8)*30/3
```


### Example 3
Researchers conducted a blind taste test of Coke versus Pepsi. Each of four people was asked which of two blinded drinks given in random order that they preferred. The data was such that 3 of the 4 people chose Coke. Assuming that this sample is representative, report a P-value for a test of the hypothesis that Coke is preferred to Pepsi using a one sided exact test.
```{r}
binom.test(3,4,alt = "greater")$p.value
```

### Example 4
Question 4

Infection rates at a hospital above 1 infection per 100 person days at risk are believed to be too high and are used as a benchmark. A hospital that had previously been above the benchmark recently had 10 infections over the last 1,787 person days at risk. About what is the one sided P-value for the relevant test of whether the hospital is *below* the standard?
```{r}
rate = 1/100
errors = 10
days = 1787
poisson.test(errors,T = days, r= rate,alternative = "less")
```  

## Example 5
Researchers would like to conduct a study of n n n healthy adults to detect a four year mean brain volume loss of .01 mm3 Assume that the standard deviation of four year volume loss in this population is .04 mm3. About what would be the value of n needed for 90% power of type one error rate of 5% one sided test versus a null hypothesis of no volume loss?
```{r}
power.t.test(power = 0.9, delta = 0.01, sd = 0.04, type = "one.sample", alt = "one.sided")$n
```  

Question 7

Researchers would like to conduct a study of 100 100 100 healthy adults to detect a four year mean brain volume loss of .01 mm3. Assume that the standard deviation of four year volume loss in this population is .04 mm3. About what would be the power of the study for a 5% one sided test versus a null hypothesis of no volume loss?
```{r}
power.t.test(n = 100, delta = 0.01, sd = 0.04, type = "one.sample", alt = "one.sided")$power
```  


## Example 7
Suppose that 18 obese subjects were randomized, 9 each, to a new diet pill and a placebo. Subjects’ body mass indices (BMIs) were measured at a baseline and again after having received the treatment or placebo for four weeks. The average difference from follow-up to the baseline (followup - baseline) was −3 kg/m2 for the treated group and 1 kg/m2 for the placebo group. The corresponding standard deviations of the differences was 1.5 kg/m2 for the treatment group and 1.8 kg/m2 for the placebo group. Does the change in BMI appear to differ between the treated and placebo groups? Assuming normality of the underlying data and a common population variance, give a pvalue for a two sided t test.  
```{r}
n1 <- n2 <- 9
x1 <- -3 ## mean of treated
x2 <- 1 ##mean of placebo
s1 <- 1.5 ## standard deviation in treated
s2 <- 1.8 ## standard deviation in placebo
sp <- sqrt(((n1 - 1) * s1^2 + (n2 - 1) * s2^2)/(n1 + n2 - 2))
ts <- (x1 - x2)/(sp * sqrt(1/n1 + 1/n2))
2 * pt(ts, n1 + n2 - 2)
```


```







